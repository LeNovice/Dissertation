{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeNovice/Dissertation/blob/main/VGG_CadenceNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCeppY1fBRsz"
      },
      "outputs": [],
      "source": [
        "USE_ORIGINAL = 0\n",
        "loss = 'categorical_crossentropy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYvbodAaO5NT"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "#For plotting the dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#Data pipeline preparation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "#model building\n",
        "from tensorflow.keras import models\n",
        "import tensorflow.keras.utils as tfutils\n",
        "import os\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJSJfW_tPA88"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 10\n",
        "\n",
        "DataSet = 'cifar10'\n",
        "#'caltech101'\n",
        "#'cifar10'\n",
        "def num_samples_per_class(ds_train, get_top_10 = False, print_all = False):\n",
        "    vals = np.unique(np.fromiter(ds_train.map(lambda x, y: y), int), return_counts=True)\n",
        "    class_list = []\n",
        "    class_hist = []\n",
        "    for val,count in zip(*vals):\n",
        "        if print_all==True:\n",
        "            print(int(val), count)\n",
        "        class_hist.append((val,count))\n",
        "    if get_top_10 == True:\n",
        "        sorted_tuple = sorted(class_hist, key=lambda t: t[-1], reverse=True)[:(NUM_CLASSES + 1)]    #+1 because we are going to remove \"backround_google\" i.e. 4\n",
        "        class_list = [x for x,y in sorted_tuple]\n",
        "    return class_list\n",
        "\n",
        "def filter_fn(x, allowed_classes:list):\n",
        "    allowed_classes = tf.constant(allowed_classes)\n",
        "    isallowed = tf.equal(allowed_classes, tf.cast(x, allowed_classes.dtype))\n",
        "    reduced_sum = tf.reduce_sum(tf.cast(isallowed, tf.float32))\n",
        "    return tf.greater(reduced_sum, tf.constant(0.))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fLIbNS2PDZ1"
      },
      "outputs": [],
      "source": [
        "if DataSet == 'caltech101':\n",
        "    ds_train, train_info = tfds.load(DataSet, split='test[0:90%]', as_supervised=True, with_info = True)\n",
        "    ds_test = tfds.load(DataSet, split='train', as_supervised=True)\n",
        "    ds_val = tfds.load(DataSet, split='test[90%:]', as_supervised=True) \n",
        "else:\n",
        "    ds_train, train_info = tfds.load(DataSet, split='train[0:80%]', as_supervised=True, with_info = True)   #taking 0 to 80% for training\n",
        "    ds_test = tfds.load(DataSet, split='test', as_supervised=True)        \n",
        "    ds_val = tfds.load(DataSet, split='test[80%:]', as_supervised=True)                                     #taking data from 80% point to the end of the dataset (100%) for validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOoGq7JtPGn8",
        "outputId": "fa2ea47e-a16d-49fc-9702-b435e89e99e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "class_list = num_samples_per_class(ds_train, get_top_10=True)\n",
        "if DataSet == 'caltech101':\n",
        "  class_list = [i for i in class_list if i != train_info.features['label'].str2int('background_google')]\n",
        "  class_list.sort()\n",
        "class_names = [train_info.features['label'].int2str(i) for i in class_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeThcLypHU4m"
      },
      "outputs": [],
      "source": [
        "resized_ds_train = ds_train.filter(lambda x, y: filter_fn(y, class_list)) # as_supervised\n",
        "resized_ds_test = ds_test.filter(lambda x, y: filter_fn(y, class_list))\n",
        "resized_ds_val = ds_val.filter(lambda x, y: filter_fn(y, class_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdPKLGVdPNrk"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "if DataSet=='caltech101':\n",
        "    IMG_SIZE = 60\n",
        "elif DataSet=='cifar10':\n",
        "    IMG_SIZE = 32\n",
        "NUM_CHANNELS = 3\n",
        "BATCH_SIZE=128\n",
        "\n",
        "input_shape = (IMG_SIZE,IMG_SIZE,NUM_CHANNELS)\n",
        "#Relabelling to avoid issues. Note that human readability is reduced by this\n",
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tf.constant(class_list, dtype=tf.int64),\n",
        "        values=tf.constant([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  dtype=tf.int64)\n",
        "    ),\n",
        "    default_value= tf.constant(0,  dtype=tf.int64)\n",
        ")\n",
        "\n",
        "#This function will be used in the graph execution hence @tf.function prefix\n",
        "@tf.function\n",
        "def map_func(label):\n",
        "    global class_list\n",
        "    global loss\n",
        "    mapped_label = table.lookup(label)\n",
        "    if loss != 'sparse_categorical_crossentropy':\n",
        "        mapped_label = tf.one_hot(indices=mapped_label, depth=NUM_CLASSES)\n",
        "    print(\"Label = \" + str(label) + \"\\t\" + \"Mapped Label = \" + str(mapped_label))\n",
        "    return mapped_label\n",
        "\n",
        "#Preprocessing done as part of the graph\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "resize_layer = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "buffer_size = 30*NUM_CLASSES\n",
        "\n",
        "#Preprocessing function which invokes above graphs\n",
        "def prepare(ds, shuffle=False, augment=False, resize_only = False):\n",
        "    global buffer_size\n",
        "    global BATCH_SIZE\n",
        "    \n",
        "\n",
        "    # Resize and rescale all datasets.\n",
        "    if resize_only==True:\n",
        "        ds = ds.map(lambda x, y: (resize_layer(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        ds = ds.map(lambda x, y: (resize_and_rescale(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size)\n",
        "        \n",
        "    # Batch all datasets.\n",
        "    #ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "    # Use data augmentation only on the training set.\n",
        "    if augment:\n",
        "        ds_aug = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        ds = ds.concatenate(ds_aug)\n",
        "\n",
        "        \n",
        "    # Use buffered prefetching on all datasets.\n",
        "    return ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmLFCHD6PgLw",
        "outputId": "88c2ea52-2cf8-471b-f363-5fa19c5e27b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label = Tensor(\"label:0\", shape=(), dtype=int64)\tMapped Label = Tensor(\"one_hot:0\", shape=(10,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "resized_ds_train = prepare(resized_ds_train, augment=True)\n",
        "resized_ds_test = prepare(resized_ds_test)\n",
        "resized_ds_val = prepare(resized_ds_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uf1KScmu9odE"
      },
      "outputs": [],
      "source": [
        "def num_samples_per_class_onehot(resized_ds_train, print_all=False):\n",
        "    if loss != 'sparse_categorical_crossentropy':\n",
        "        vals = np.unique(np.fromiter(resized_ds_train.map(lambda x, y: tf.argmax(y)), int), return_counts=True)\n",
        "    else:\n",
        "        vals = np.unique(np.fromiter(resized_ds_train.map(lambda x, y: y), int), return_counts=True)\n",
        "    class_list = []\n",
        "    class_hist = []\n",
        "    for val,count in zip(*vals):\n",
        "        if print_all==True:\n",
        "            print(int(val), count)\n",
        "        class_hist.append((val,count))\n",
        "    class_hist.sort()\n",
        "    return class_hist\n",
        "#Post prepare function, all the labels will be converted to one hot encoders. In order to get class-wise distribution, we will need to convert each one hot encoder into its label (temporarily)\n",
        "#We need a new function to handle it\n",
        "class_hist = num_samples_per_class_onehot(resized_ds_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ftnZ5OyvQB98",
        "outputId": "21fcdccd-5ae6-4372-e0d3-6e5cc61eea52"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Quantization scheme experiments'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#reg = tf.keras.regularizers.L2(0.01)\n",
        "reg = tf.keras.regularizers.L1L2(l1 =0.0, l2 = 0.1)\n",
        "#reg = tf.keras.regularizers.L1L2(l1 =0.0, l2 = 0.0)\n",
        "#beta_regularizer = 0.1\n",
        "#gamma_regularizer = 0.1\n",
        "\n",
        "model = models.Sequential()\n",
        "kernel_size = (3,3)\n",
        "pool_size = (2,2)\n",
        "if USE_ORIGINAL == 1:\n",
        "\tdisplay(\"Default quantization scheme\")\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same', input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNELS)))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.1))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.3))\n",
        "\t\n",
        "\tmodel.add(layers.Flatten())\n",
        "\tmodel.add(layers.Dense(128, kernel_initializer='he_uniform', kernel_regularizer = reg))\n",
        "\tif 0:\n",
        "\t\t\"\"\"\n",
        "\t\tThe converter quantizes batchnorm iff it follows a Conv2D layer. Hence we remove this BatchNorm layer (although it helps in accuracy).\n",
        "\t\tSo we trade off accuracy for smaller model size\n",
        "\t\t\"\"\"\n",
        "\t\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\tmodel.add(layers.Dense(NUM_CLASSES, kernel_regularizer = reg))\n",
        "\tmodel.add(layers.Softmax())\n",
        "else:\n",
        "\tdisplay(\"Quantization scheme experiments\")\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same', input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNELS)))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.1))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.3))\n",
        "\t\n",
        "\tmodel.add(layers.Flatten())\n",
        "\tmodel.add(layers.Dense(128, kernel_initializer='he_uniform', kernel_regularizer = reg))\n",
        "\tif 0:\n",
        "\t\t\"\"\"\n",
        "\t\tThe converter quantizes batchnorm iff it follows a Conv2D layer. Hence we remove this BatchNorm layer (although it helps in accuracy).\n",
        "\t\tSo we trade off accuracy for smaller model size\n",
        "\t\t\"\"\"\n",
        "\t\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\tmodel.add(layers.Dense(NUM_CLASSES, kernel_regularizer = reg))\n",
        "\tmodel.add(layers.Softmax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-aANPwedhNH"
      },
      "outputs": [],
      "source": [
        "def get_class_weights(class_hist):\n",
        "    \"\"\"\n",
        "    Returns the class weights as a tf.Tensor. Class weights are inverse of the class frequencies\n",
        "    Class frequencies are the number of samples of each class which we calculate in earlier steps\n",
        "    \"\"\"\n",
        "    inv_freq = tf.convert_to_tensor([1.0/count for label, count in class_hist], dtype=tf.float32)\n",
        "    return tfutils.normalize(inv_freq)\n",
        "\n",
        "\n",
        "def weightedloss(y_true, y_pred, gamma, class_weight):\n",
        "    \"\"\"\n",
        "    We assume that all arguments coming into this function are tf.Tensors type\n",
        "    class_weights are basically alpha in focal loss paper\n",
        "    \"\"\"\n",
        "    #ones = tf.convert_to_tensor(np.ones(shape=len(y_true)))\n",
        "    a = tf.math.multiply(tf.math.pow(tf.math.subtract(1.0, y_pred), gamma), tf.math.log(y_pred))  #((1-pt)^gamma)log(pt)\n",
        "    b = tf.math.multiply(-1.0, class_weight)                                                          #-alpha\n",
        "    b = tf.math.multiply(b,a)    \n",
        "    b = tf.math.multiply(b, y_true)\n",
        "    return b\n",
        "class WeightedLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, gamma, class_weight=np.ones(shape=NUM_CLASSES, dtype=np.float32)):\n",
        "        super().__init__()\n",
        "        self.gamma = tf.convert_to_tensor(gamma)\n",
        "        self.class_weight = tf.convert_to_tensor(class_weight, dtype=tf.float32)\n",
        "    def call(self, y_true, y_pred):\n",
        "        return weightedloss(y_true, y_pred, self.gamma, self.class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHRlWtV83IeV"
      },
      "outputs": [],
      "source": [
        "Learning_Rate = 1e-5\n",
        "\n",
        "#tf.keras.optimizers.Adam(learning_rate=Learning_Rate)     #OR tf.keras.optimizers.SGD(learning_rate=Learning_Rate, momentum=0.9)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=Learning_Rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHFaNgqtwZGz"
      },
      "outputs": [],
      "source": [
        "###EITHER\n",
        "\n",
        "#!pip install focal-loss\n",
        "#from focal_loss import SparseCategoricalFocalLoss \n",
        "#model.compile( optimizer = opt, loss = SparseCategoricalFocalLoss(gamma=2), metrics=['accuracy'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFFBTJNwLAcA"
      },
      "outputs": [],
      "source": [
        "###OR\n",
        "#model.compile( optimizer = opt, loss = loss, metrics=['accuracy'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "pmqZtduVbl-2",
        "outputId": "746479f4-7cd7-4c97-892f-2dbde153dbab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
              "array([[0.31036258, 0.31453058, 0.31515762, 0.31531474, 0.3157083 ,\n",
              "        0.3159449 , 0.31657755, 0.3168949 , 0.31809038, 0.32354245]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "###OR\n",
        "class_wts = get_class_weights(class_hist)\n",
        "display(class_wts)\n",
        "model.compile( optimizer = opt, loss = WeightedLoss(gamma=2.0, class_weight=class_wts), metrics=['accuracy'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL7YFZKvbn92"
      },
      "outputs": [],
      "source": [
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNi4QKkp27-d",
        "outputId": "8128fdfa-3736-4f50-ed45-0c0d236dc5f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "625/625 [==============================] - 46s 58ms/step - loss: 105.0355 - accuracy: 0.1088 - val_loss: 94.0939 - val_accuracy: 0.1090\n",
            "Epoch 2/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 84.7404 - accuracy: 0.1125 - val_loss: 75.9796 - val_accuracy: 0.1210\n",
            "Epoch 3/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 68.4255 - accuracy: 0.1172 - val_loss: 61.3412 - val_accuracy: 0.1370\n",
            "Epoch 4/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 55.2110 - accuracy: 0.1224 - val_loss: 49.4630 - val_accuracy: 0.1525\n",
            "Epoch 5/80\n",
            "625/625 [==============================] - 35s 55ms/step - loss: 44.4874 - accuracy: 0.1285 - val_loss: 39.8277 - val_accuracy: 0.1715\n",
            "Epoch 6/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 35.8018 - accuracy: 0.1431 - val_loss: 32.0397 - val_accuracy: 0.1905\n",
            "Epoch 7/80\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 28.8004 - accuracy: 0.1575 - val_loss: 25.7809 - val_accuracy: 0.2020\n",
            "Epoch 8/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 23.1916 - accuracy: 0.1761 - val_loss: 20.7845 - val_accuracy: 0.2040\n",
            "Epoch 9/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 18.7281 - accuracy: 0.2027 - val_loss: 16.8212 - val_accuracy: 0.2185\n",
            "Epoch 10/80\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 15.1959 - accuracy: 0.2297 - val_loss: 13.6917 - val_accuracy: 0.2330\n",
            "Epoch 11/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 12.4105 - accuracy: 0.2499 - val_loss: 11.2264 - val_accuracy: 0.2405\n",
            "Epoch 12/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 10.2164 - accuracy: 0.2579 - val_loss: 9.2840 - val_accuracy: 0.2485\n",
            "Epoch 13/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 8.4872 - accuracy: 0.2644 - val_loss: 7.7527 - val_accuracy: 0.2445\n",
            "Epoch 14/80\n",
            "625/625 [==============================] - 38s 61ms/step - loss: 7.1235 - accuracy: 0.2678 - val_loss: 6.5450 - val_accuracy: 0.2340\n",
            "Epoch 15/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 6.0480 - accuracy: 0.2678 - val_loss: 5.5924 - val_accuracy: 0.2425\n",
            "Epoch 16/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 5.1990 - accuracy: 0.2654 - val_loss: 4.8400 - val_accuracy: 0.2360\n",
            "Epoch 17/80\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 4.5280 - accuracy: 0.2622 - val_loss: 4.2446 - val_accuracy: 0.2425\n",
            "Epoch 18/80\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 3.9964 - accuracy: 0.2646 - val_loss: 3.7716 - val_accuracy: 0.2480\n",
            "Epoch 19/80\n",
            "625/625 [==============================] - 39s 62ms/step - loss: 3.5726 - accuracy: 0.2639 - val_loss: 3.3922 - val_accuracy: 0.2525\n",
            "Epoch 20/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 3.2304 - accuracy: 0.2648 - val_loss: 3.0830 - val_accuracy: 0.2565\n",
            "Epoch 21/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 2.9489 - accuracy: 0.2661 - val_loss: 2.8260 - val_accuracy: 0.2540\n",
            "Epoch 22/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 2.7126 - accuracy: 0.2623 - val_loss: 2.6080 - val_accuracy: 0.2505\n",
            "Epoch 23/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 2.5108 - accuracy: 0.2643 - val_loss: 2.4209 - val_accuracy: 0.2465\n",
            "Epoch 24/80\n",
            "625/625 [==============================] - 35s 57ms/step - loss: 2.3364 - accuracy: 0.2602 - val_loss: 2.2580 - val_accuracy: 0.2515\n",
            "Epoch 25/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 2.1837 - accuracy: 0.2565 - val_loss: 2.1141 - val_accuracy: 0.2460\n",
            "Epoch 26/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 2.0477 - accuracy: 0.2555 - val_loss: 1.9848 - val_accuracy: 0.2485\n",
            "Epoch 27/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 1.9242 - accuracy: 0.2481 - val_loss: 1.8666 - val_accuracy: 0.2415\n",
            "Epoch 28/80\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 1.8099 - accuracy: 0.2421 - val_loss: 1.7561 - val_accuracy: 0.2455\n",
            "Epoch 29/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 1.7025 - accuracy: 0.1978 - val_loss: 1.6518 - val_accuracy: 0.1940\n",
            "Epoch 30/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 1.6012 - accuracy: 0.1911 - val_loss: 1.5532 - val_accuracy: 0.1935\n",
            "Epoch 31/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 1.5054 - accuracy: 0.1893 - val_loss: 1.4599 - val_accuracy: 0.1905\n",
            "Epoch 32/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 1.4145 - accuracy: 0.1862 - val_loss: 1.3714 - val_accuracy: 0.1935\n",
            "Epoch 33/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 1.3281 - accuracy: 0.1871 - val_loss: 1.2871 - val_accuracy: 0.1860\n",
            "Epoch 34/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 1.2461 - accuracy: 0.1851 - val_loss: 1.2071 - val_accuracy: 0.1440\n",
            "Epoch 35/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 1.1680 - accuracy: 0.1680 - val_loss: 1.1307 - val_accuracy: 0.1410\n",
            "Epoch 36/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 1.0938 - accuracy: 0.1667 - val_loss: 1.0583 - val_accuracy: 0.1425\n",
            "Epoch 37/80\n",
            "625/625 [==============================] - 35s 57ms/step - loss: 1.0233 - accuracy: 0.1671 - val_loss: 0.9897 - val_accuracy: 0.1445\n",
            "Epoch 38/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 0.9562 - accuracy: 0.1676 - val_loss: 0.9241 - val_accuracy: 0.1390\n",
            "Epoch 39/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 0.8924 - accuracy: 0.1683 - val_loss: 0.8620 - val_accuracy: 0.1445\n",
            "Epoch 40/80\n",
            "625/625 [==============================] - 35s 57ms/step - loss: 0.8319 - accuracy: 0.1689 - val_loss: 0.8032 - val_accuracy: 0.1445\n",
            "Epoch 41/80\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 0.7744 - accuracy: 0.1689 - val_loss: 0.7471 - val_accuracy: 0.1435\n",
            "Epoch 42/80\n",
            "625/625 [==============================] - 35s 57ms/step - loss: 0.7199 - accuracy: 0.1695 - val_loss: 0.6941 - val_accuracy: 0.1450\n",
            "Epoch 43/80\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.6683 - accuracy: 0.1701 - val_loss: 0.6438 - val_accuracy: 0.1435\n",
            "Epoch 44/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 0.6195 - accuracy: 0.1702 - val_loss: 0.5965 - val_accuracy: 0.1455\n",
            "Epoch 45/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 0.5735 - accuracy: 0.1709 - val_loss: 0.5519 - val_accuracy: 0.1455\n",
            "Epoch 46/80\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 0.5302 - accuracy: 0.1703 - val_loss: 0.5099 - val_accuracy: 0.1455\n",
            "Epoch 47/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 0.4894 - accuracy: 0.1705 - val_loss: 0.4704 - val_accuracy: 0.1425\n",
            "Epoch 48/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 0.4512 - accuracy: 0.1707 - val_loss: 0.4332 - val_accuracy: 0.1420\n",
            "Epoch 49/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 0.4153 - accuracy: 0.1716 - val_loss: 0.3988 - val_accuracy: 0.1450\n",
            "Epoch 50/80\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 0.3818 - accuracy: 0.1711 - val_loss: 0.3662 - val_accuracy: 0.1440\n",
            "Epoch 51/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 0.3505 - accuracy: 0.1718 - val_loss: 0.3359 - val_accuracy: 0.1385\n",
            "Epoch 52/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 0.3214 - accuracy: 0.1719 - val_loss: 0.3082 - val_accuracy: 0.1490\n",
            "Epoch 53/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 0.2944 - accuracy: 0.1721 - val_loss: 0.2822 - val_accuracy: 0.1475\n",
            "Epoch 54/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 0.2694 - accuracy: 0.1722 - val_loss: 0.2581 - val_accuracy: 0.1455\n",
            "Epoch 55/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 0.2463 - accuracy: 0.1722 - val_loss: 0.2359 - val_accuracy: 0.1475\n",
            "Epoch 56/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 0.2251 - accuracy: 0.1725 - val_loss: 0.2156 - val_accuracy: 0.1455\n",
            "Epoch 57/80\n",
            "625/625 [==============================] - 35s 55ms/step - loss: 0.2055 - accuracy: 0.1724 - val_loss: 0.1968 - val_accuracy: 0.1455\n",
            "Epoch 58/80\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.1876 - accuracy: 0.1732 - val_loss: 0.1799 - val_accuracy: 0.1485\n",
            "Epoch 59/80\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 0.1712 - accuracy: 0.1731 - val_loss: 0.1643 - val_accuracy: 0.1450\n",
            "Epoch 60/80\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.1564 - accuracy: 0.1733 - val_loss: 0.1503 - val_accuracy: 0.1465\n",
            "Epoch 61/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 0.1429 - accuracy: 0.1734 - val_loss: 0.1372 - val_accuracy: 0.1440\n",
            "Epoch 62/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 0.1307 - accuracy: 0.1740 - val_loss: 0.1262 - val_accuracy: 0.1465\n",
            "Epoch 63/80\n",
            "625/625 [==============================] - 35s 57ms/step - loss: 0.1199 - accuracy: 0.1736 - val_loss: 0.1154 - val_accuracy: 0.1450\n",
            "Epoch 64/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 0.1101 - accuracy: 0.1738 - val_loss: 0.1065 - val_accuracy: 0.1480\n",
            "Epoch 65/80\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.1015 - accuracy: 0.1731 - val_loss: 0.0982 - val_accuracy: 0.1455\n",
            "Epoch 66/80\n",
            "625/625 [==============================] - 35s 57ms/step - loss: 0.0939 - accuracy: 0.1749 - val_loss: 0.0912 - val_accuracy: 0.1420\n",
            "Epoch 67/80\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.0873 - accuracy: 0.1776 - val_loss: 0.0849 - val_accuracy: 0.1530\n",
            "Epoch 68/80\n",
            "625/625 [==============================] - 37s 59ms/step - loss: 0.0815 - accuracy: 0.1827 - val_loss: 0.0797 - val_accuracy: 0.1725\n",
            "Epoch 69/80\n",
            "625/625 [==============================] - 35s 56ms/step - loss: 0.0766 - accuracy: 0.1852 - val_loss: 0.0752 - val_accuracy: 0.1700\n",
            "Epoch 70/80\n",
            "625/625 [==============================] - 35s 57ms/step - loss: 0.0725 - accuracy: 0.1864 - val_loss: 0.0716 - val_accuracy: 0.1770\n",
            "Epoch 71/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 0.0691 - accuracy: 0.1885 - val_loss: 0.0683 - val_accuracy: 0.1730\n",
            "Epoch 72/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 0.0663 - accuracy: 0.1900 - val_loss: 0.0659 - val_accuracy: 0.1710\n",
            "Epoch 73/80\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 0.0641 - accuracy: 0.1901 - val_loss: 0.0641 - val_accuracy: 0.1785\n",
            "Epoch 74/80\n",
            "625/625 [==============================] - 35s 55ms/step - loss: 0.0623 - accuracy: 0.1918 - val_loss: 0.0626 - val_accuracy: 0.1745\n",
            "Epoch 75/80\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 0.0610 - accuracy: 0.1911 - val_loss: 0.0614 - val_accuracy: 0.1735\n",
            "Epoch 76/80\n",
            "625/625 [==============================] - 33s 52ms/step - loss: 0.0600 - accuracy: 0.1914 - val_loss: 0.0605 - val_accuracy: 0.1750\n",
            "Epoch 77/80\n",
            "625/625 [==============================] - 34s 55ms/step - loss: 0.0594 - accuracy: 0.1911 - val_loss: 0.0601 - val_accuracy: 0.1780\n",
            "Epoch 78/80\n",
            "625/625 [==============================] - 32s 52ms/step - loss: 0.0589 - accuracy: 0.1908 - val_loss: 0.0596 - val_accuracy: 0.1750\n",
            "Epoch 79/80\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 0.0586 - accuracy: 0.1908 - val_loss: 0.0593 - val_accuracy: 0.1735\n",
            "Epoch 80/80\n",
            "625/625 [==============================] - 33s 52ms/step - loss: 0.0583 - accuracy: 0.1908 - val_loss: 0.0594 - val_accuracy: 0.1695\n"
          ]
        }
      ],
      "source": [
        "resized_ds_train = resized_ds_train.batch(BATCH_SIZE)\n",
        "resized_ds_val = resized_ds_val.batch(BATCH_SIZE)\n",
        "\n",
        "h = model.fit( resized_ds_train, epochs=80, validation_data = resized_ds_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FuOyiBsTQkYL",
        "outputId": "6661e7fd-16c4-4d8d-9128-8d3f993f3623"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5eodErTxg9BJ",
        "outputId": "1cee0a7b-35ca-46d7-e03d-73e09266558b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(h.history['accuracy'])\n",
        "plt.plot(h.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pxSSK5SPhnKL"
      },
      "outputs": [],
      "source": [
        "#Evaluation and confusion matrix creation:\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "x_test = np.asarray(list(map(lambda x: x[0], tfds.as_numpy(resized_ds_test))))\n",
        "y_test_orig = np.asarray(list(map(lambda x: x[1], tfds.as_numpy(resized_ds_test))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Tg4EdPBuc7fW",
        "outputId": "41ae1ae9-b3af-46ff-aea2-9f72f39af70c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sYYhORws1NnZ",
        "outputId": "60963b9f-2b09-47ee-db9a-c43b7073960f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if loss!='sparse_categorical_crossentropy':\n",
        "    false_arr = np.full(shape=len(class_list), fill_value = False)\n",
        "    #y_pred = np.empty(shape=y_test_orig.shape[-1])\n",
        "    i=0\n",
        "    for i, pred in enumerate(predictions):\n",
        "        temp_arr = copy.deepcopy(false_arr)\n",
        "        np.put(temp_arr, np.argmax(pred), True)\n",
        "        if i==0:\n",
        "            y_pred = copy.deepcopy(temp_arr)\n",
        "        else:\n",
        "            y_pred = np.vstack([y_pred, temp_arr])\n",
        "    display(y_pred.shape)\n",
        "else:\n",
        "    y_pred = np.argmax(predictions, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o-iQ19WTaE9s",
        "outputId": "33dd0bd1-0589-4c8d-e1e9-5d85deee0dd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(y_test_orig.shape)\n",
        "display(y_pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "phcwIL8RJQNQ",
        "outputId": "dc669df1-e3fd-460d-d284-750289a96161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,  20,  28,  11,   0,   0,   0, 941,   0],\n",
              "       [  0,   0, 495, 176,  27,   0,   0,   0, 302,   0],\n",
              "       [  0,   0, 559, 214,  23,   0,   0,   0, 204,   0],\n",
              "       [  0,   0, 250, 190,  43,   0,   0,   0, 517,   0],\n",
              "       [  0,   0, 359, 165,  35,   0,   0,   0, 441,   0],\n",
              "       [  0,   0, 242, 190,  50,   0,   0,   0, 518,   0],\n",
              "       [  0,   0,   2,  13,   7,   0,   0,   0, 978,   0],\n",
              "       [  0,   0, 296, 166,  45,   0,   0,   0, 493,   0],\n",
              "       [  0,   0,  14,  23,  10,   0,   0,   0, 953,   0],\n",
              "       [  0,   0,  17,  40,  11,   0,   0,   0, 932,   0]])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.00      0.00      0.00      1000\n",
            "        deer       0.00      0.00      0.00      1000\n",
            "        frog       0.25      0.56      0.34      1000\n",
            "         dog       0.16      0.19      0.17      1000\n",
            "        bird       0.13      0.04      0.06      1000\n",
            "       horse       0.00      0.00      0.00      1000\n",
            "  automobile       0.00      0.00      0.00      1000\n",
            "         cat       0.00      0.00      0.00      1000\n",
            "        ship       0.15      0.95      0.26      1000\n",
            "       truck       0.00      0.00      0.00      1000\n",
            "\n",
            "   micro avg       0.17      0.17      0.17     10000\n",
            "   macro avg       0.07      0.17      0.08     10000\n",
            "weighted avg       0.07      0.17      0.08     10000\n",
            " samples avg       0.17      0.17      0.17     10000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print('Confusion Matrix')\n",
        "if loss != 'sparse_categorical_crossentropy':\n",
        "    matrix = confusion_matrix(y_test_orig.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "else:\n",
        "    matrix = confusion_matrix(y_test_orig, y_pred)\n",
        "display(matrix)\n",
        "\n",
        "# Print Classification Report\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_orig, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7NaFdDuTQoyT"
      },
      "outputs": [],
      "source": [
        "def ret_as_numpy():\n",
        "    #test = tfds.load(DataSet, split='test', as_supervised=True)\n",
        "    #test = prepare(test)\n",
        "    #test = tfds.as_numpy(test)\n",
        "    return tfds.as_numpy(resized_ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Si_MguzMQuZL"
      },
      "outputs": [],
      "source": [
        "test_as_np = ret_as_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xWYWlODgQrFy"
      },
      "outputs": [],
      "source": [
        "def evaluate_float_model(model, test):\n",
        "    test_labels = []\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        test_labels.append(np.argmax(test_example[-1]))\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        #display(test_image.shape)\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        \n",
        "        # Run inference.\n",
        "        output = model(test_image, training=False)\n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = output.numpy()\n",
        "        digit = np.argmax(output[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BOHIU_J3QxE7",
        "outputId": "fd9284b3-2228-40ee-a175-3d1b6f7ba28b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Float test_accuracy: 0.1737\n"
          ]
        }
      ],
      "source": [
        "test_accuracy_Float = evaluate_float_model(model, test_as_np)\n",
        "\n",
        "print('Float test_accuracy:', test_accuracy_Float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Q2Is9IY-Oo"
      },
      "source": [
        "Float checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i9kUxj-4wNG"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "#To make the whole model aware of quantization,\n",
        "quantize_model = tfmot.quantization.keras.quantize_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWycqRCE4yBu"
      },
      "outputs": [],
      "source": [
        "q_aware_model = quantize_model(model)\n",
        "#TODO: Check why this is not possible with Adam\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=Learning_Rate, momentum=0.9)\n",
        "q_aware_model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "q_aware_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blO0aYaP44O8"
      },
      "outputs": [],
      "source": [
        "h = q_aware_model.fit(resized_ds_train, epochs=5, validation_data = resized_ds_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WButHzSy5BTH"
      },
      "outputs": [],
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbugbXtI5Ecm"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXBCHsjF5JiG"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(interpreter, test):\n",
        "    test_labels = []\n",
        "\n",
        "\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        test_labels.append(np.argmax(test_example[-1]))\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        interpreter.set_tensor(input_index, test_image)\n",
        "        \n",
        "        # Run inference.\n",
        "        interpreter.invoke()\n",
        "        \n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = interpreter.tensor(output_index)\n",
        "        digit = np.argmax(output()[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWyXRobN5NU_"
      },
      "outputs": [],
      "source": [
        "#Models obtained from TfLiteConverter can be run in Python with Interpreter.\n",
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "#Since TensorFlow Lite pre-plans tensor allocations to optimize inference, the user needs to call allocate_tensors() before any inference.\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter, test_as_np)\n",
        "\n",
        "print('Quant TFLite test_accuracy:', test_accuracy)\n",
        "#print('Quant TF test accuracy:', q_aware_model_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxEHJlru5PlG"
      },
      "outputs": [],
      "source": [
        "MODEL_DIR = \"CadenceNet_Float\"\n",
        "model.save(MODEL_DIR, save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHzmQxaT5R3W"
      },
      "outputs": [],
      "source": [
        "!pip install -U tf2onnx==1.8.4\n",
        "!python -m tf2onnx.convert --saved-model /content/CadenceNet_Float/ --output /content/CadenceNetOriginal_Float.onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UgJyPkX5UKe"
      },
      "outputs": [],
      "source": [
        "quant_file = \"/content/CadenceNetOriginal_QAT.tflite\"\n",
        "open(quant_file, \"wb\").write(quantized_tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5iITOiiRP0M"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Float model in Mb: \", os.path.getsize(\"/content/CadenceNetOriginal_Float.onnx\") / float(2**20))\n",
        "print(\"Quantized model in Mb: \", os.path.getsize(quant_file) / float(2**20))\n",
        "print(\"Float Model Accuracy: \", test_accuracy_Float)\n",
        "print(\"Quantized Model Accuracy: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh_ERgvr1BNy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}