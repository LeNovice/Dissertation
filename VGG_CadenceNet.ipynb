{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeNovice/Dissertation/blob/main/VGG_CadenceNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BCeppY1fBRsz"
      },
      "outputs": [],
      "source": [
        "USE_ORIGINAL = 0\n",
        "loss = 'categorical_crossentropy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IYvbodAaO5NT"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "#For plotting the dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#Data pipeline preparation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "#model building\n",
        "from tensorflow.keras import models\n",
        "import tensorflow.keras.utils as tfutils\n",
        "import os\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bJSJfW_tPA88"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 10\n",
        "\n",
        "DataSet = 'caltech101'\n",
        "#'caltech101'\n",
        "#'cifar10'\n",
        "def num_samples_per_class(ds_train, get_top_10 = False, print_all = False):\n",
        "    vals = np.unique(np.fromiter(ds_train.map(lambda x, y: y), int), return_counts=True)\n",
        "    class_list = []\n",
        "    class_hist = []\n",
        "    for val,count in zip(*vals):\n",
        "        if print_all==True:\n",
        "            print(int(val), count)\n",
        "        class_hist.append((val,count))\n",
        "    if get_top_10 == True:\n",
        "        sorted_tuple = sorted(class_hist, key=lambda t: t[-1], reverse=True)[:(NUM_CLASSES + 1)]    #+1 because we are going to remove \"backround_google\" i.e. 4\n",
        "        class_list = [x for x,y in sorted_tuple]\n",
        "    return class_list\n",
        "\n",
        "def filter_fn(x, allowed_classes:list):\n",
        "    allowed_classes = tf.constant(allowed_classes)\n",
        "    isallowed = tf.equal(allowed_classes, tf.cast(x, allowed_classes.dtype))\n",
        "    reduced_sum = tf.reduce_sum(tf.cast(isallowed, tf.float32))\n",
        "    return tf.greater(reduced_sum, tf.constant(0.))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2fLIbNS2PDZ1"
      },
      "outputs": [],
      "source": [
        "if DataSet == 'caltech101':\n",
        "    ds_train, train_info = tfds.load(DataSet, split='test[0:90%]', as_supervised=True, with_info = True)\n",
        "    ds_test = tfds.load(DataSet, split='train', as_supervised=True)\n",
        "    ds_val = tfds.load(DataSet, split='test[90%:]', as_supervised=True) \n",
        "else:\n",
        "    ds_train, train_info = tfds.load(DataSet, split='train[0:80%]', as_supervised=True, with_info = True)   #taking 0 to 80% for training\n",
        "    ds_test = tfds.load(DataSet, split='test', as_supervised=True)        \n",
        "    ds_val = tfds.load(DataSet, split='test[80%:]', as_supervised=True)                                     #taking data from 80% point to the end of the dataset (100%) for validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QOoGq7JtPGn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e0fae9-8343-4598-eedd-aba8ce2019f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "class_list = num_samples_per_class(ds_train, get_top_10=True)\n",
        "if DataSet == 'caltech101':\n",
        "  class_list = [i for i in class_list if i != train_info.features['label'].str2int('background_google')]\n",
        "  class_list.sort()\n",
        "class_names = [train_info.features['label'].int2str(i) for i in class_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VeThcLypHU4m"
      },
      "outputs": [],
      "source": [
        "resized_ds_train = ds_train.filter(lambda x, y: filter_fn(y, class_list)) # as_supervised\n",
        "resized_ds_test = ds_test.filter(lambda x, y: filter_fn(y, class_list))\n",
        "resized_ds_val = ds_val.filter(lambda x, y: filter_fn(y, class_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QdPKLGVdPNrk"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "if DataSet=='caltech101':\n",
        "    IMG_SIZE = 60\n",
        "elif DataSet=='cifar10':\n",
        "    IMG_SIZE = 32\n",
        "NUM_CHANNELS = 3\n",
        "BATCH_SIZE=128\n",
        "\n",
        "input_shape = (IMG_SIZE,IMG_SIZE,NUM_CHANNELS)\n",
        "#Relabelling to avoid issues. Note that human readability is reduced by this\n",
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tf.constant(class_list, dtype=tf.int64),\n",
        "        values=tf.constant([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  dtype=tf.int64)\n",
        "    ),\n",
        "    default_value= tf.constant(0,  dtype=tf.int64)\n",
        ")\n",
        "\n",
        "#This function will be used in the graph execution hence @tf.function prefix\n",
        "@tf.function\n",
        "def map_func(label):\n",
        "    global class_list\n",
        "    global loss\n",
        "    mapped_label = table.lookup(label)\n",
        "    if loss != 'sparse_categorical_crossentropy':\n",
        "        mapped_label = tf.one_hot(indices=mapped_label, depth=NUM_CLASSES)\n",
        "    print(\"Label = \" + str(label) + \"\\t\" + \"Mapped Label = \" + str(mapped_label))\n",
        "    return mapped_label\n",
        "\n",
        "#Preprocessing done as part of the graph\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "resize_layer = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "buffer_size = 30*NUM_CLASSES\n",
        "\n",
        "#Preprocessing function which invokes above graphs\n",
        "def prepare(ds, shuffle=False, augment=False, resize_only = False):\n",
        "    global buffer_size\n",
        "    global BATCH_SIZE\n",
        "    \n",
        "\n",
        "    # Resize and rescale all datasets.\n",
        "    if resize_only==True:\n",
        "        ds = ds.map(lambda x, y: (resize_layer(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        ds = ds.map(lambda x, y: (resize_and_rescale(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size)\n",
        "        \n",
        "    # Batch all datasets.\n",
        "    #ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "    # Use data augmentation only on the training set.\n",
        "    if augment:\n",
        "        ds_aug = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        ds = ds.concatenate(ds_aug)\n",
        "\n",
        "        \n",
        "    # Use buffered prefetching on all datasets.\n",
        "    return ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmLFCHD6PgLw",
        "outputId": "8c059e55-e9d4-41e6-920c-0373446b5b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label = Tensor(\"label:0\", shape=(), dtype=int64)\tMapped Label = Tensor(\"one_hot:0\", shape=(10,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "resized_ds_train = prepare(resized_ds_train, augment=True)\n",
        "resized_ds_test = prepare(resized_ds_test)\n",
        "resized_ds_val = prepare(resized_ds_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uf1KScmu9odE"
      },
      "outputs": [],
      "source": [
        "def num_samples_per_class_onehot(resized_ds_train, print_all=False):\n",
        "    if loss != 'sparse_categorical_crossentropy':\n",
        "        vals = np.unique(np.fromiter(resized_ds_train.map(lambda x, y: tf.argmax(y)), int), return_counts=True)\n",
        "    else:\n",
        "        vals = np.unique(np.fromiter(resized_ds_train.map(lambda x, y: y), int), return_counts=True)\n",
        "    class_list = []\n",
        "    class_hist = []\n",
        "    for val,count in zip(*vals):\n",
        "        if print_all==True:\n",
        "            print(int(val), count)\n",
        "        class_hist.append((val,count))\n",
        "    class_hist.sort()\n",
        "    return class_hist\n",
        "#Post prepare function, all the labels will be converted to one hot encoders. In order to get class-wise distribution, we will need to convert each one hot encoder into its label (temporarily)\n",
        "#We need a new function to handle it\n",
        "class_hist = num_samples_per_class_onehot(resized_ds_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ftnZ5OyvQB98",
        "outputId": "733537db-912d-4242-9802-69de018b586f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Quantization scheme experiments'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#reg = tf.keras.regularizers.L2(0.01)\n",
        "reg = tf.keras.regularizers.L1L2(l1 =0.0, l2 = 0.1)\n",
        "#reg = tf.keras.regularizers.L1L2(l1 =0.0, l2 = 0.0)\n",
        "#beta_regularizer = 0.1\n",
        "#gamma_regularizer = 0.1\n",
        "\n",
        "model = models.Sequential()\n",
        "kernel_size = (3,3)\n",
        "pool_size = (2,2)\n",
        "if USE_ORIGINAL == 1:\n",
        "\tdisplay(\"Default quantization scheme\")\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same', input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNELS)))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.1))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.3))\n",
        "\t\n",
        "\tmodel.add(layers.Flatten())\n",
        "\tmodel.add(layers.Dense(128, kernel_initializer='he_uniform', kernel_regularizer = reg))\n",
        "\tif 0:\n",
        "\t\t\"\"\"\n",
        "\t\tThe converter quantizes batchnorm iff it follows a Conv2D layer. Hence we remove this BatchNorm layer (although it helps in accuracy).\n",
        "\t\tSo we trade off accuracy for smaller model size\n",
        "\t\t\"\"\"\n",
        "\t\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\tmodel.add(layers.Dense(NUM_CLASSES, kernel_regularizer = reg))\n",
        "\tmodel.add(layers.Softmax())\n",
        "else:\n",
        "\tdisplay(\"Quantization scheme experiments\")\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same', input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNELS)))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.1))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.3))\n",
        "\t\n",
        "\tmodel.add(layers.Flatten())\n",
        "\tmodel.add(layers.Dense(128, kernel_initializer='he_uniform', kernel_regularizer = reg))\n",
        "\tif 0:\n",
        "\t\t\"\"\"\n",
        "\t\tThe converter quantizes batchnorm iff it follows a Conv2D layer. Hence we remove this BatchNorm layer (although it helps in accuracy).\n",
        "\t\tSo we trade off accuracy for smaller model size\n",
        "\t\t\"\"\"\n",
        "\t\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\tmodel.add(layers.Dense(NUM_CLASSES, kernel_regularizer = reg))\n",
        "\tmodel.add(layers.Softmax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "B-aANPwedhNH"
      },
      "outputs": [],
      "source": [
        "def get_class_weights(class_hist):\n",
        "    \"\"\"\n",
        "    Returns the class weights as a tf.Tensor. Class weights are inverse of the class frequencies\n",
        "    Class frequencies are the number of samples of each class which we calculate in earlier steps\n",
        "    \"\"\"\n",
        "    inv_freq = tf.convert_to_tensor([1.0/count for label, count in class_hist], dtype=tf.float32)\n",
        "    return tfutils.normalize(inv_freq)\n",
        "\n",
        "\n",
        "def weightedloss(y_true, y_pred, gamma, class_weight):\n",
        "    \"\"\"\n",
        "    We assume that all arguments coming into this function are tf.Tensors type\n",
        "    class_weights are basically alpha in focal loss paper\n",
        "    \"\"\"\n",
        "    #ones = tf.convert_to_tensor(np.ones(shape=len(y_true)))\n",
        "    a = tf.math.multiply(tf.math.pow(tf.math.subtract(1.0, y_pred), gamma), tf.math.log(y_pred))  #((1-pt)^gamma)log(pt)\n",
        "    b = tf.math.multiply(-1.0, class_weight)                                                          #-alpha\n",
        "    b = tf.math.multiply(b,a)    \n",
        "    b = tf.math.multiply(b, y_true)\n",
        "    return b\n",
        "class WeightedLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, gamma, class_weight=np.ones(shape=NUM_CLASSES, dtype=np.float32)):\n",
        "        super().__init__()\n",
        "        self.gamma = tf.convert_to_tensor(gamma)\n",
        "        self.class_weight = tf.convert_to_tensor(class_weight, dtype=tf.float32)\n",
        "    def call(self, y_true, y_pred):\n",
        "        return weightedloss(y_true, y_pred, self.gamma, self.class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fHRlWtV83IeV"
      },
      "outputs": [],
      "source": [
        "Learning_Rate = 1e-5\n",
        "\n",
        "#tf.keras.optimizers.Adam(learning_rate=Learning_Rate)     #OR tf.keras.optimizers.SGD(learning_rate=Learning_Rate, momentum=0.9)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=Learning_Rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DHFaNgqtwZGz"
      },
      "outputs": [],
      "source": [
        "###EITHER\n",
        "\n",
        "#!pip install focal-loss\n",
        "#from focal_loss import SparseCategoricalFocalLoss \n",
        "#model.compile( optimizer = opt, loss = SparseCategoricalFocalLoss(gamma=2), metrics=['accuracy'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nFFBTJNwLAcA"
      },
      "outputs": [],
      "source": [
        "###OR\n",
        "#model.compile( optimizer = opt, loss = loss, metrics=['accuracy'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pmqZtduVbl-2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "cd0cb110-511e-46a9-b32a-3e4c1c510bd0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
              "array([[0.05302042, 0.42233506, 0.43227234, 0.5403404 , 0.1032111 ,\n",
              "        0.09772114, 0.47106603, 0.2401513 , 0.05309704, 0.193385  ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "###OR\n",
        "class_wts = get_class_weights(class_hist)\n",
        "display(class_wts)\n",
        "model.compile( optimizer = opt, loss = WeightedLoss(gamma=2.0, class_weight=class_wts), metrics=['accuracy'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HL7YFZKvbn92"
      },
      "outputs": [],
      "source": [
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KNi4QKkp27-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c835ce8-6903-4d6a-9394-c32c11c5a374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "44/44 [==============================] - 26s 169ms/step - loss: 116.1094 - accuracy: 0.1353 - val_loss: 114.9356 - val_accuracy: 0.0897\n",
            "Epoch 2/80\n",
            "44/44 [==============================] - 6s 143ms/step - loss: 113.9027 - accuracy: 0.1246 - val_loss: 112.7617 - val_accuracy: 0.1030\n",
            "Epoch 3/80\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 111.7527 - accuracy: 0.1184 - val_loss: 110.6438 - val_accuracy: 0.1429\n",
            "Epoch 4/80\n",
            "44/44 [==============================] - 6s 136ms/step - loss: 109.6588 - accuracy: 0.1211 - val_loss: 108.5798 - val_accuracy: 0.1694\n",
            "Epoch 5/80\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 107.6186 - accuracy: 0.1253 - val_loss: 106.5678 - val_accuracy: 0.1628\n",
            "Epoch 6/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 105.6290 - accuracy: 0.1177 - val_loss: 104.6055 - val_accuracy: 0.1827\n",
            "Epoch 7/80\n",
            "44/44 [==============================] - 6s 143ms/step - loss: 103.6897 - accuracy: 0.1256 - val_loss: 102.6916 - val_accuracy: 0.2060\n",
            "Epoch 8/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 101.7971 - accuracy: 0.1233 - val_loss: 100.8244 - val_accuracy: 0.2159\n",
            "Epoch 9/80\n",
            "44/44 [==============================] - 6s 144ms/step - loss: 99.9509 - accuracy: 0.1332 - val_loss: 99.0022 - val_accuracy: 0.2126\n",
            "Epoch 10/80\n",
            "44/44 [==============================] - 6s 137ms/step - loss: 98.1495 - accuracy: 0.1272 - val_loss: 97.2234 - val_accuracy: 0.2159\n",
            "Epoch 11/80\n",
            "44/44 [==============================] - 6s 128ms/step - loss: 96.3896 - accuracy: 0.1357 - val_loss: 95.4865 - val_accuracy: 0.2326\n",
            "Epoch 12/80\n",
            "44/44 [==============================] - 8s 173ms/step - loss: 94.6717 - accuracy: 0.1458 - val_loss: 93.7905 - val_accuracy: 0.2392\n",
            "Epoch 13/80\n",
            "44/44 [==============================] - 6s 143ms/step - loss: 92.9944 - accuracy: 0.1416 - val_loss: 92.1337 - val_accuracy: 0.2425\n",
            "Epoch 14/80\n",
            "44/44 [==============================] - 6s 136ms/step - loss: 91.3556 - accuracy: 0.1420 - val_loss: 90.5153 - val_accuracy: 0.2591\n",
            "Epoch 15/80\n",
            "44/44 [==============================] - 6s 131ms/step - loss: 89.7546 - accuracy: 0.1465 - val_loss: 88.9338 - val_accuracy: 0.2558\n",
            "Epoch 16/80\n",
            "44/44 [==============================] - 6s 143ms/step - loss: 88.1907 - accuracy: 0.1469 - val_loss: 87.3882 - val_accuracy: 0.2625\n",
            "Epoch 17/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 86.6614 - accuracy: 0.1476 - val_loss: 85.8773 - val_accuracy: 0.2691\n",
            "Epoch 18/80\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 85.1663 - accuracy: 0.1571 - val_loss: 84.4004 - val_accuracy: 0.2791\n",
            "Epoch 19/80\n",
            "44/44 [==============================] - 6s 141ms/step - loss: 83.7055 - accuracy: 0.1559 - val_loss: 82.9563 - val_accuracy: 0.2791\n",
            "Epoch 20/80\n",
            "44/44 [==============================] - 5s 122ms/step - loss: 82.2765 - accuracy: 0.1542 - val_loss: 81.5439 - val_accuracy: 0.2957\n",
            "Epoch 21/80\n",
            "44/44 [==============================] - 7s 155ms/step - loss: 80.8787 - accuracy: 0.1614 - val_loss: 80.1625 - val_accuracy: 0.2990\n",
            "Epoch 22/80\n",
            "44/44 [==============================] - 6s 133ms/step - loss: 79.5121 - accuracy: 0.1578 - val_loss: 78.8112 - val_accuracy: 0.2957\n",
            "Epoch 23/80\n",
            "44/44 [==============================] - 5s 123ms/step - loss: 78.1746 - accuracy: 0.1674 - val_loss: 77.4892 - val_accuracy: 0.2824\n",
            "Epoch 24/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 76.8658 - accuracy: 0.1694 - val_loss: 76.1954 - val_accuracy: 0.2990\n",
            "Epoch 25/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 75.5853 - accuracy: 0.1715 - val_loss: 74.9293 - val_accuracy: 0.3056\n",
            "Epoch 26/80\n",
            "44/44 [==============================] - 6s 144ms/step - loss: 74.3326 - accuracy: 0.1834 - val_loss: 73.6900 - val_accuracy: 0.2990\n",
            "Epoch 27/80\n",
            "44/44 [==============================] - 6s 128ms/step - loss: 73.1055 - accuracy: 0.1938 - val_loss: 72.4769 - val_accuracy: 0.3156\n",
            "Epoch 28/80\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 71.9046 - accuracy: 0.1879 - val_loss: 71.2892 - val_accuracy: 0.3223\n",
            "Epoch 29/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 70.7289 - accuracy: 0.1872 - val_loss: 70.1263 - val_accuracy: 0.3156\n",
            "Epoch 30/80\n",
            "44/44 [==============================] - 6s 144ms/step - loss: 69.5775 - accuracy: 0.1899 - val_loss: 68.9874 - val_accuracy: 0.3389\n",
            "Epoch 31/80\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 68.4503 - accuracy: 0.1985 - val_loss: 67.8720 - val_accuracy: 0.3256\n",
            "Epoch 32/80\n",
            "44/44 [==============================] - 6s 145ms/step - loss: 67.3454 - accuracy: 0.1965 - val_loss: 66.7795 - val_accuracy: 0.3389\n",
            "Epoch 33/80\n",
            "44/44 [==============================] - 6s 137ms/step - loss: 66.2635 - accuracy: 0.2093 - val_loss: 65.7092 - val_accuracy: 0.3522\n",
            "Epoch 34/80\n",
            "44/44 [==============================] - 6s 133ms/step - loss: 65.2037 - accuracy: 0.2036 - val_loss: 64.6605 - val_accuracy: 0.3522\n",
            "Epoch 35/80\n",
            "44/44 [==============================] - 6s 145ms/step - loss: 64.1649 - accuracy: 0.2158 - val_loss: 63.6329 - val_accuracy: 0.3522\n",
            "Epoch 36/80\n",
            "44/44 [==============================] - 5s 123ms/step - loss: 63.1475 - accuracy: 0.2261 - val_loss: 62.6258 - val_accuracy: 0.3654\n",
            "Epoch 37/80\n",
            "44/44 [==============================] - 6s 145ms/step - loss: 62.1500 - accuracy: 0.2208 - val_loss: 61.6388 - val_accuracy: 0.3621\n",
            "Epoch 38/80\n",
            "44/44 [==============================] - 6s 143ms/step - loss: 61.1724 - accuracy: 0.2358 - val_loss: 60.6713 - val_accuracy: 0.3688\n",
            "Epoch 39/80\n",
            "44/44 [==============================] - 5s 123ms/step - loss: 60.2141 - accuracy: 0.2369 - val_loss: 59.7227 - val_accuracy: 0.3953\n",
            "Epoch 40/80\n",
            "44/44 [==============================] - 6s 137ms/step - loss: 59.2742 - accuracy: 0.2406 - val_loss: 58.7927 - val_accuracy: 0.3754\n",
            "Epoch 41/80\n",
            "44/44 [==============================] - 6s 142ms/step - loss: 58.3533 - accuracy: 0.2358 - val_loss: 57.8808 - val_accuracy: 0.4020\n",
            "Epoch 42/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 57.4499 - accuracy: 0.2520 - val_loss: 56.9866 - val_accuracy: 0.3953\n",
            "Epoch 43/80\n",
            "44/44 [==============================] - 6s 141ms/step - loss: 56.5636 - accuracy: 0.2664 - val_loss: 56.1095 - val_accuracy: 0.4020\n",
            "Epoch 44/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 55.6946 - accuracy: 0.2655 - val_loss: 55.2491 - val_accuracy: 0.4120\n",
            "Epoch 45/80\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 54.8421 - accuracy: 0.2729 - val_loss: 54.4051 - val_accuracy: 0.4319\n",
            "Epoch 46/80\n",
            "44/44 [==============================] - 6s 141ms/step - loss: 54.0061 - accuracy: 0.2765 - val_loss: 53.5769 - val_accuracy: 0.4219\n",
            "Epoch 47/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 53.1851 - accuracy: 0.2828 - val_loss: 52.7644 - val_accuracy: 0.4452\n",
            "Epoch 48/80\n",
            "44/44 [==============================] - 6s 135ms/step - loss: 52.3798 - accuracy: 0.2873 - val_loss: 51.9670 - val_accuracy: 0.4485\n",
            "Epoch 49/80\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 51.5897 - accuracy: 0.2964 - val_loss: 51.1843 - val_accuracy: 0.4884\n",
            "Epoch 50/80\n",
            "44/44 [==============================] - 6s 145ms/step - loss: 50.8140 - accuracy: 0.3049 - val_loss: 50.4162 - val_accuracy: 0.4917\n",
            "Epoch 51/80\n",
            "44/44 [==============================] - 6s 146ms/step - loss: 50.0529 - accuracy: 0.3098 - val_loss: 49.6621 - val_accuracy: 0.4884\n",
            "Epoch 52/80\n",
            "44/44 [==============================] - 6s 127ms/step - loss: 49.3049 - accuracy: 0.3135 - val_loss: 48.9217 - val_accuracy: 0.5083\n",
            "Epoch 53/80\n",
            "44/44 [==============================] - 6s 148ms/step - loss: 48.5712 - accuracy: 0.3128 - val_loss: 48.1947 - val_accuracy: 0.5050\n",
            "Epoch 54/80\n",
            "44/44 [==============================] - 5s 123ms/step - loss: 47.8506 - accuracy: 0.3362 - val_loss: 47.4808 - val_accuracy: 0.5349\n",
            "Epoch 55/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 47.1430 - accuracy: 0.3236 - val_loss: 46.7797 - val_accuracy: 0.5249\n",
            "Epoch 56/80\n",
            "44/44 [==============================] - 6s 142ms/step - loss: 46.4477 - accuracy: 0.3335 - val_loss: 46.0910 - val_accuracy: 0.5116\n",
            "Epoch 57/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 45.7649 - accuracy: 0.3425 - val_loss: 45.4144 - val_accuracy: 0.5216\n",
            "Epoch 58/80\n",
            "44/44 [==============================] - 6s 137ms/step - loss: 45.0940 - accuracy: 0.3580 - val_loss: 44.7498 - val_accuracy: 0.5449\n",
            "Epoch 59/80\n",
            "44/44 [==============================] - 6s 131ms/step - loss: 44.4350 - accuracy: 0.3578 - val_loss: 44.0967 - val_accuracy: 0.5316\n",
            "Epoch 60/80\n",
            "44/44 [==============================] - 6s 146ms/step - loss: 43.7874 - accuracy: 0.3652 - val_loss: 43.4549 - val_accuracy: 0.5482\n",
            "Epoch 61/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 43.1509 - accuracy: 0.3801 - val_loss: 42.8242 - val_accuracy: 0.5681\n",
            "Epoch 62/80\n",
            "44/44 [==============================] - 6s 143ms/step - loss: 42.5255 - accuracy: 0.3785 - val_loss: 42.2043 - val_accuracy: 0.5648\n",
            "Epoch 63/80\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 41.9106 - accuracy: 0.3978 - val_loss: 41.5949 - val_accuracy: 0.5581\n",
            "Epoch 64/80\n",
            "44/44 [==============================] - 6s 143ms/step - loss: 41.3062 - accuracy: 0.4033 - val_loss: 40.9958 - val_accuracy: 0.5714\n",
            "Epoch 65/80\n",
            "44/44 [==============================] - 6s 143ms/step - loss: 40.7120 - accuracy: 0.4199 - val_loss: 40.4067 - val_accuracy: 0.5880\n",
            "Epoch 66/80\n",
            "44/44 [==============================] - 6s 145ms/step - loss: 40.1275 - accuracy: 0.4242 - val_loss: 39.8275 - val_accuracy: 0.5880\n",
            "Epoch 67/80\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 39.5529 - accuracy: 0.4311 - val_loss: 39.2578 - val_accuracy: 0.5980\n",
            "Epoch 68/80\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 38.9879 - accuracy: 0.4195 - val_loss: 38.6975 - val_accuracy: 0.5980\n",
            "Epoch 69/80\n",
            "44/44 [==============================] - 7s 150ms/step - loss: 38.4318 - accuracy: 0.4411 - val_loss: 38.1463 - val_accuracy: 0.6279\n",
            "Epoch 70/80\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 37.8850 - accuracy: 0.4487 - val_loss: 37.6041 - val_accuracy: 0.6013\n",
            "Epoch 71/80\n",
            "44/44 [==============================] - 6s 144ms/step - loss: 37.3469 - accuracy: 0.4521 - val_loss: 37.0707 - val_accuracy: 0.6312\n",
            "Epoch 72/80\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 36.8176 - accuracy: 0.4743 - val_loss: 36.5457 - val_accuracy: 0.6312\n",
            "Epoch 73/80\n",
            "44/44 [==============================] - 6s 145ms/step - loss: 36.2966 - accuracy: 0.4689 - val_loss: 36.0292 - val_accuracy: 0.6146\n",
            "Epoch 74/80\n",
            "44/44 [==============================] - 5s 123ms/step - loss: 35.7839 - accuracy: 0.4807 - val_loss: 35.5207 - val_accuracy: 0.6047\n",
            "Epoch 75/80\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 35.2794 - accuracy: 0.4829 - val_loss: 35.0203 - val_accuracy: 0.6412\n",
            "Epoch 76/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 34.7827 - accuracy: 0.4980 - val_loss: 34.5276 - val_accuracy: 0.6146\n",
            "Epoch 77/80\n",
            "44/44 [==============================] - 6s 142ms/step - loss: 34.2937 - accuracy: 0.4917 - val_loss: 34.0426 - val_accuracy: 0.6312\n",
            "Epoch 78/80\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 33.8123 - accuracy: 0.5101 - val_loss: 33.5650 - val_accuracy: 0.6545\n",
            "Epoch 79/80\n",
            "44/44 [==============================] - 6s 146ms/step - loss: 33.3384 - accuracy: 0.5047 - val_loss: 33.0948 - val_accuracy: 0.6744\n",
            "Epoch 80/80\n",
            "44/44 [==============================] - 6s 129ms/step - loss: 32.8716 - accuracy: 0.5081 - val_loss: 32.6316 - val_accuracy: 0.6777\n"
          ]
        }
      ],
      "source": [
        "resized_ds_train = resized_ds_train.batch(BATCH_SIZE)\n",
        "resized_ds_val = resized_ds_val.batch(BATCH_SIZE)\n",
        "\n",
        "h = model.fit( resized_ds_train, epochs=80, validation_data = resized_ds_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FuOyiBsTQkYL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "77d5e712-521c-4b8c-a921-995da58e6a68"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5eodErTxg9BJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "27224e5d-7f19-42c0-bd82-9e7af1277fa6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(h.history['accuracy'])\n",
        "plt.plot(h.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pxSSK5SPhnKL"
      },
      "outputs": [],
      "source": [
        "#Evaluation and confusion matrix creation:\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "x_test = np.asarray(list(map(lambda x: x[0], tfds.as_numpy(resized_ds_test))))\n",
        "y_test_orig = np.asarray(list(map(lambda x: x[1], tfds.as_numpy(resized_ds_test))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Tg4EdPBuc7fW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dff13bf-b063-4c87-c62c-589f42e456b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 15ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sYYhORws1NnZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b10c162f-b49e-4719-b40e-972f555baf6a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(300, 10)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if loss!='sparse_categorical_crossentropy':\n",
        "    false_arr = np.full(shape=len(class_list), fill_value = False)\n",
        "    #y_pred = np.empty(shape=y_test_orig.shape[-1])\n",
        "    i=0\n",
        "    for i, pred in enumerate(predictions):\n",
        "        temp_arr = copy.deepcopy(false_arr)\n",
        "        np.put(temp_arr, np.argmax(pred), True)\n",
        "        if i==0:\n",
        "            y_pred = copy.deepcopy(temp_arr)\n",
        "        else:\n",
        "            y_pred = np.vstack([y_pred, temp_arr])\n",
        "    display(y_pred.shape)\n",
        "else:\n",
        "    y_pred = np.argmax(predictions, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "o-iQ19WTaE9s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e18c33de-bdaa-4086-d78a-e78955c062d3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(300, 10)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(300, 10)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(y_test_orig.shape)\n",
        "display(y_pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "phcwIL8RJQNQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "97bfa930-c1a5-4128-c1fd-d0eee1edf1d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[11,  0, 14,  0,  0,  1,  0,  1,  3,  0],\n",
              "       [ 0,  7,  3,  5,  0,  2,  1,  8,  2,  2],\n",
              "       [ 0,  0, 30,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0,  0,  3, 15,  0,  2,  4,  2,  3,  1],\n",
              "       [ 0,  0,  2,  4,  5, 17,  1,  1,  0,  0],\n",
              "       [ 0,  0,  1,  0,  0, 29,  0,  0,  0,  0],\n",
              "       [ 0,  0,  1,  3,  0,  2, 21,  0,  2,  1],\n",
              "       [ 2,  2,  1,  0,  0,  0,  0, 25,  0,  0],\n",
              "       [ 0,  1,  0,  4,  0,  1,  0,  0, 24,  0],\n",
              "       [ 0,  2,  5,  5,  0,  0,  1,  0,  8,  9]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   airplanes       0.85      0.37      0.51        30\n",
            "      bonsai       0.58      0.23      0.33        30\n",
            "    car_side       0.50      1.00      0.67        30\n",
            "  chandelier       0.42      0.50      0.45        30\n",
            "       faces       1.00      0.17      0.29        30\n",
            "  faces_easy       0.54      0.97      0.69        30\n",
            "       ketch       0.75      0.70      0.72        30\n",
            "    leopards       0.68      0.83      0.75        30\n",
            "  motorbikes       0.57      0.80      0.67        30\n",
            "       watch       0.69      0.30      0.42        30\n",
            "\n",
            "   micro avg       0.59      0.59      0.59       300\n",
            "   macro avg       0.66      0.59      0.55       300\n",
            "weighted avg       0.66      0.59      0.55       300\n",
            " samples avg       0.59      0.59      0.59       300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Confusion Matrix')\n",
        "if loss != 'sparse_categorical_crossentropy':\n",
        "    matrix = confusion_matrix(y_test_orig.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "else:\n",
        "    matrix = confusion_matrix(y_test_orig, y_pred)\n",
        "display(matrix)\n",
        "\n",
        "# Print Classification Report\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_orig, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7NaFdDuTQoyT"
      },
      "outputs": [],
      "source": [
        "def ret_as_numpy():\n",
        "    #test = tfds.load(DataSet, split='test', as_supervised=True)\n",
        "    #test = prepare(test)\n",
        "    #test = tfds.as_numpy(test)\n",
        "    return tfds.as_numpy(resized_ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Si_MguzMQuZL"
      },
      "outputs": [],
      "source": [
        "test_as_np = ret_as_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xWYWlODgQrFy"
      },
      "outputs": [],
      "source": [
        "def evaluate_float_model(model, test):\n",
        "    test_labels = []\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        test_labels.append(np.argmax(test_example[-1]))\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        #display(test_image.shape)\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        \n",
        "        # Run inference.\n",
        "        output = model(test_image, training=False)\n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = output.numpy()\n",
        "        digit = np.argmax(output[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BOHIU_J3QxE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eae0e4f-1e78-4728-b2a6-eecea367c59e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Float test_accuracy: 0.5866666666666667\n"
          ]
        }
      ],
      "source": [
        "test_accuracy_Float = evaluate_float_model(model, test_as_np)\n",
        "\n",
        "print('Float test_accuracy:', test_accuracy_Float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Q2Is9IY-Oo"
      },
      "source": [
        "Float checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "#To make the whole model aware of quantization,\n",
        "quantize_model = tfmot.quantization.keras.quantize_model"
      ],
      "metadata": {
        "id": "5i9kUxj-4wNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1076af3e-bab6-4ce3-cf48-4d6659982ab9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/238.9 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_aware_model = quantize_model(model)\n",
        "#TODO: Check why this is not possible with Adam\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=Learning_Rate, momentum=0.9)\n",
        "q_aware_model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "q_aware_model.summary()"
      ],
      "metadata": {
        "id": "yWycqRCE4yBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc6b4bf-9e44-4938-a2b0-8bfc1282ef06"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLay  (None, 60, 60, 3)        3         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " quant_conv2d (QuantizeWrapp  (None, 60, 60, 32)       961       \n",
            " erV2)                                                           \n",
            "                                                                 \n",
            " quant_batch_normalization (  (None, 60, 60, 32)       129       \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_re_lu (QuantizeWrappe  (None, 60, 60, 32)       3         \n",
            " rV2)                                                            \n",
            "                                                                 \n",
            " quant_conv2d_1 (QuantizeWra  (None, 60, 60, 32)       9313      \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_1  (None, 60, 60, 32)       129       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_1 (QuantizeWrap  (None, 60, 60, 32)       3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_max_pooling2d (Quanti  (None, 30, 30, 32)       1         \n",
            " zeWrapperV2)                                                    \n",
            "                                                                 \n",
            " quant_dropout (QuantizeWrap  (None, 30, 30, 32)       1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_conv2d_2 (QuantizeWra  (None, 30, 30, 64)       18625     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_2  (None, 30, 30, 64)       257       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_2 (QuantizeWrap  (None, 30, 30, 64)       3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_conv2d_3 (QuantizeWra  (None, 30, 30, 64)       37057     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_3  (None, 30, 30, 64)       257       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_3 (QuantizeWrap  (None, 30, 30, 64)       3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_max_pooling2d_1 (Quan  (None, 15, 15, 64)       1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_dropout_1 (QuantizeWr  (None, 15, 15, 64)       1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_conv2d_4 (QuantizeWra  (None, 15, 15, 128)      74113     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_4  (None, 15, 15, 128)      513       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_4 (QuantizeWrap  (None, 15, 15, 128)      3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_conv2d_5 (QuantizeWra  (None, 15, 15, 128)      147841    \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_5  (None, 15, 15, 128)      513       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_5 (QuantizeWrap  (None, 15, 15, 128)      3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_max_pooling2d_2 (Quan  (None, 7, 7, 128)        1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_dropout_2 (QuantizeWr  (None, 7, 7, 128)        1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_flatten (QuantizeWrap  (None, 6272)             1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dense (QuantizeWrappe  (None, 128)              802945    \n",
            " rV2)                                                            \n",
            "                                                                 \n",
            " quant_re_lu_6 (QuantizeWrap  (None, 128)              3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dropout_3 (QuantizeWr  (None, 128)              1         \n",
            " apperV2)                                                        \n",
            "                                                                 \n",
            " quant_dense_1 (QuantizeWrap  (None, 10)               1295      \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_softmax (QuantizeWrap  (None, 10)               1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,093,981\n",
            "Trainable params: 1,092,138\n",
            "Non-trainable params: 1,843\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = q_aware_model.fit(resized_ds_train, epochs=5, validation_data = resized_ds_val)"
      ],
      "metadata": {
        "id": "blO0aYaP44O8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d58fa3d-c4b5-4e30-8c9b-9aaba2bd52a8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 13s 219ms/step - loss: 34.2132 - accuracy: 0.5713 - val_loss: 34.0957 - val_accuracy: 0.6645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WButHzSy5BTH",
        "outputId": "8a2db44c-9003-42a7-c427-e89fa4496aad"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbugbXtI5Ecm",
        "outputId": "b7c2adc0-b9d6-4060-de41-a9c99f1cbb36"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 48). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(interpreter, test):\n",
        "    test_labels = []\n",
        "\n",
        "\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        test_labels.append(np.argmax(test_example[-1]))\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        interpreter.set_tensor(input_index, test_image)\n",
        "        \n",
        "        # Run inference.\n",
        "        interpreter.invoke()\n",
        "        \n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = interpreter.tensor(output_index)\n",
        "        digit = np.argmax(output()[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "iXBCHsjF5JiG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Models obtained from TfLiteConverter can be run in Python with Interpreter.\n",
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "#Since TensorFlow Lite pre-plans tensor allocations to optimize inference, the user needs to call allocate_tensors() before any inference.\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter, test_as_np)\n",
        "\n",
        "print('Quant TFLite test_accuracy:', test_accuracy)\n",
        "#print('Quant TF test accuracy:', q_aware_model_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWyXRobN5NU_",
        "outputId": "27079449-02e3-4b17-b5a8-d2936eb4bd58"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Quant TFLite test_accuracy: 0.37666666666666665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = \"CadenceNet_Float\"\n",
        "model.save(MODEL_DIR, save_format=\"tf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxEHJlru5PlG",
        "outputId": "7f5a5f25-d7eb-486a-befa-0b32a2d77069"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tf2onnx==1.8.4\n",
        "!python -m tf2onnx.convert --saved-model /content/CadenceNet_Float/ --output /content/CadenceNetOriginal_Float.onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHzmQxaT5R3W",
        "outputId": "9e67a521-6112-4e4c-85f5-3af872cb0179"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf2onnx==1.8.4\n",
            "  Downloading tf2onnx-1.8.4-py3-none-any.whl (345 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m345.3/345.3 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tf2onnx==1.8.4) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.8/dist-packages (from tf2onnx==1.8.4) (1.22.4)\n",
            "Collecting onnx>=1.4.1\n",
            "  Downloading onnx-1.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from tf2onnx==1.8.4) (2.25.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from tf2onnx==1.8.4) (23.1.21)\n",
            "Collecting protobuf<4,>=3.20.2\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx>=1.4.1->tf2onnx==1.8.4) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx==1.8.4) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx==1.8.4) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx==1.8.4) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx==1.8.4) (2022.12.7)\n",
            "Installing collected packages: protobuf, onnx, tf2onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.13.1 protobuf-3.20.3 tf2onnx-1.8.4\n",
            "2023-03-04 09:09:49.553782: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-04 09:09:49.553890: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-04 09:09:49.553910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "2023-03-04 09:09:52,393 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
            "2023-03-04 09:09:53,509 - INFO - Signatures found in model: [serving_default].\n",
            "2023-03-04 09:09:53,509 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
            "2023-03-04 09:09:53,509 - INFO - Output names: ['softmax']\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tf2onnx/tf_loader.py:557: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
            "2023-03-04 09:09:53,745 - WARNING - From /usr/local/lib/python3.8/dist-packages/tf2onnx/tf_loader.py:557: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
            "2023-03-04 09:09:53,838 - INFO - Using tensorflow=2.11.0, onnx=1.13.1, tf2onnx=1.8.4/cd55bf\n",
            "2023-03-04 09:09:53,839 - INFO - Using opset <onnx, 9>\n",
            "2023-03-04 09:09:53,848 - INFO - Computed 0 values for constant folding\n",
            "2023-03-04 09:09:53,941 - INFO - Optimizing ONNX model\n",
            "2023-03-04 09:09:54,026 - INFO - After optimization: BatchNormalization -6 (6->0), Cast -1 (1->0), Const -24 (41->17), Identity -9 (9->0), Transpose -28 (30->2)\n",
            "2023-03-04 09:09:54,032 - INFO - \n",
            "2023-03-04 09:09:54,032 - INFO - Successfully converted TensorFlow model /content/CadenceNet_Float/ to ONNX\n",
            "2023-03-04 09:09:54,032 - INFO - Model inputs: ['conv2d_input:0']\n",
            "2023-03-04 09:09:54,032 - INFO - Model outputs: ['softmax']\n",
            "2023-03-04 09:09:54,032 - INFO - ONNX model is saved at /content/CadenceNetOriginal_Float.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quant_file = \"/content/CadenceNetOriginal_QAT.tflite\"\n",
        "open(quant_file, \"wb\").write(quantized_tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UgJyPkX5UKe",
        "outputId": "7d66d673-69aa-464e-a246-c3a1e34eef53"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1112856"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5iITOiiRP0M",
        "outputId": "ad16bddd-6c6d-48d1-840f-d036feb45994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Float model in Mb:  4.170186996459961\n",
            "Quantized model in Mb:  1.0613021850585938\n",
            "Float Model Accuracy:  0.5866666666666667\n",
            "Quantized Model Accuracy:  0.37666666666666665\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Float model in Mb: \", os.path.getsize(\"/content/CadenceNetOriginal_Float.onnx\") / float(2**20))\n",
        "print(\"Quantized model in Mb: \", os.path.getsize(quant_file) / float(2**20))\n",
        "print(\"Float Model Accuracy: \", test_accuracy_Float)\n",
        "print(\"Quantized Model Accuracy: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "1fOfhD35IW0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f1f0b0-e38b-4ed5-8052-8c5ff91bcd20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.14.1-cp38-cp38-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (23.1.21)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (23.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (1.7.1)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (3.20.3)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime) (1.2.1)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install onnxruntime\n",
        "import onnxruntime as rt\n",
        "\n",
        "sess = rt.InferenceSession(\"/content/CadenceNetOriginal_Float.onnx\")\n",
        "input_name = sess.get_inputs()[0].name\n",
        "output_name = sess.get_outputs()[0].name\n",
        "x = np.random.random((1,IMG_SIZE,IMG_SIZE,NUM_CHANNELS))\n",
        "x = x.astype(np.float32)\n",
        "res = sess.run([output_name], {input_name: x})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xh_ERgvr1BNy"
      },
      "execution_count": 40,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}